{"cells":[{"cell_type":"markdown","source":["Lab 3:\n","- Carlos Jarrin\n","- Fausto Yugcha"],"metadata":{"id":"HEij2UBdffzM"},"id":"HEij2UBdffzM"},{"cell_type":"markdown","id":"e2c88e42-50d4-4b4d-bdf1-894bcff1a41d","metadata":{"id":"e2c88e42-50d4-4b4d-bdf1-894bcff1a41d"},"source":["# NLP and Neural Networks\n","\n","In this exercise, we'll apply our knowledge of neural networks to process natural language. As we did in the bigram exercise, the goal of this lab is to predict the next word, given the previous one."]},{"cell_type":"markdown","id":"5132d376-54d7-48c3-a52c-ac3d94ed798b","metadata":{"id":"5132d376-54d7-48c3-a52c-ac3d94ed798b"},"source":["### Data set\n","\n","Load the text from \"One Hundred Years of Solitude\" that we used in our bigrams exercise. It's located in the data folder."]},{"cell_type":"code","execution_count":1,"id":"VjJEjVhGH9WI","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38612,"status":"ok","timestamp":1726345211927,"user":{"displayName":"fgony","userId":"12699453911390145003"},"user_tz":300},"id":"VjJEjVhGH9WI","outputId":"59bc18b4-88f5-443f-cfdf-0ca1feb9ad8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"9e309d79-7746-40e3-8a02-3cc7b45c16ac","metadata":{"id":"9e309d79-7746-40e3-8a02-3cc7b45c16ac"},"source":["### Important note:\n","\n","Start with a smaller part of the text. Maybe the first 10 parragraphs, as the number of tokens rapidly increases as we add more text.\n","\n","Later you can use a bigger corpus."]},{"cell_type":"markdown","id":"3d1393d6-7cbf-4e8e-a699-0f0cd28982a3","metadata":{"id":"3d1393d6-7cbf-4e8e-a699-0f0cd28982a3"},"source":["Don't forget to prepare the data by generating the corresponding tokens."]},{"cell_type":"code","execution_count":2,"id":"9bbced32-a252-48b0-bc8f-cecfdcf1ec2e","metadata":{"id":"9bbced32-a252-48b0-bc8f-cecfdcf1ec2e","executionInfo":{"status":"ok","timestamp":1726345222805,"user_tz":300,"elapsed":8653,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from nltk import bigrams\n","from nltk.tokenize import TreebankWordTokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n","\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"id":"bmeYOB2ZIxUy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":803,"status":"ok","timestamp":1726345225260,"user":{"displayName":"fgony","userId":"12699453911390145003"},"user_tz":300},"id":"bmeYOB2ZIxUy","outputId":"3ff14da4-d1d7-4267-dfee-c1d13051acb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokens = len(tokens)=6293\n"]}],"source":["# Cargar el texto y tokenizar\n","tokenizer = TreebankWordTokenizer()\n","text = open('/content/drive/MyDrive/NLP/datos/cap1.txt', 'r').read().lower()\n","tokens = tokenizer.tokenize(text)\n","print(f\"tokens = {len(tokens)=}\")"]},{"cell_type":"markdown","id":"7681843a-18f0-4d7c-9b02-83015f4383e1","metadata":{"id":"7681843a-18f0-4d7c-9b02-83015f4383e1"},"source":["### Let's prepare the data set.\n","\n","Our neural network needs to have an input X and an output y. Remember that these sets are numerical, so you'd need something to map the tokens into numbers, and viceversa."]},{"cell_type":"code","execution_count":4,"id":"29c10640-f146-478a-a1a4-d2e747af5ea6","metadata":{"id":"29c10640-f146-478a-a1a4-d2e747af5ea6","executionInfo":{"status":"ok","timestamp":1726345227784,"user_tz":300,"elapsed":245,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Generar bigramas (pares de palabras)\n","bigram_list = list(bigrams(tokens))"]},{"cell_type":"code","execution_count":5,"id":"FxjSpRfGJw34","metadata":{"id":"FxjSpRfGJw34","executionInfo":{"status":"ok","timestamp":1726345228985,"user_tz":300,"elapsed":249,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["X = [bigram[0] for bigram in bigram_list] # Primera palabra del bigrama\n","y = [bigram[1] for bigram in bigram_list] # Segunda palabra del bigrama"]},{"cell_type":"code","execution_count":6,"id":"0PdcrSf2SYuh","metadata":{"id":"0PdcrSf2SYuh","executionInfo":{"status":"ok","timestamp":1726345230491,"user_tz":300,"elapsed":237,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Convertir las palabras a una representación numérica\n","vectorizer = CountVectorizer()\n","X_vectorized = vectorizer.fit_transform(X)"]},{"cell_type":"code","execution_count":7,"id":"6YhzKGMnVKpl","metadata":{"id":"6YhzKGMnVKpl","executionInfo":{"status":"ok","timestamp":1726345232041,"user_tz":300,"elapsed":224,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Dividir los datos en entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"code","execution_count":8,"id":"yIJBTpu9QaZR","metadata":{"id":"yIJBTpu9QaZR","executionInfo":{"status":"ok","timestamp":1726345233062,"user_tz":300,"elapsed":236,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Codificar las etiquetas\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Convertir los datos a tensores\n","X_tensor = torch.tensor(X_vectorized.toarray(), dtype = torch.float32)\n","y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n","\n","# Dividir en conjunto de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size = 0.2, random_state = 0)"]},{"cell_type":"code","execution_count":null,"id":"5984fd00-bdbf-4403-a341-b7ef83138db2","metadata":{"id":"5984fd00-bdbf-4403-a341-b7ef83138db2"},"outputs":[],"source":["# Note that our vectors are integers, which can be thought as a categorical variables.\n","# torch provides the one_hot method, that would generate tensors suitable for our nn\n","# make sure that the dtype of your tensor is float."]},{"cell_type":"code","source":["type(X_tensor)\n","type(y_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJBJV2zCONWZ","executionInfo":{"status":"ok","timestamp":1726345235104,"user_tz":300,"elapsed":204,"user":{"displayName":"fgony","userId":"12699453911390145003"}},"outputId":"a478f177-560f-42e2-cf8b-a2b1d3bdb359"},"id":"bJBJV2zCONWZ","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","id":"cda25114-c6ae-4e07-a743-12e10cd77796","metadata":{"id":"cda25114-c6ae-4e07-a743-12e10cd77796"},"source":["### Network design\n","To start, we are going to have a very simple network. Define a single layer network"]},{"cell_type":"code","execution_count":10,"id":"Qx0BrDKOaAo6","metadata":{"id":"Qx0BrDKOaAo6","executionInfo":{"status":"ok","timestamp":1726345237010,"user_tz":300,"elapsed":209,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Parámetros de la red\n","input_size = X_train.shape[1]\n","hidden_size = 128  # Ajustado para más capas ocultas\n","output_size = len(label_encoder.classes_)\n","dropout_rate = 0.3  # Para evitar el sobreajuste"]},{"cell_type":"code","execution_count":11,"id":"99c50d1e-3842-451e-8ede-1c68dddf3843","metadata":{"id":"99c50d1e-3842-451e-8ede-1c68dddf3843","executionInfo":{"status":"ok","timestamp":1726345238501,"user_tz":300,"elapsed":235,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Definir una red neuronal más profunda\n","class ImprovedNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(ImprovedNN, self).__init__()\n","        # Primera capa densa\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu1 = nn.ReLU()\n","        # Segunda capa densa\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.relu2 = nn.ReLU()\n","        # Dropout para evitar sobreajuste\n","        self.dropout = nn.Dropout(dropout_rate)\n","        # Capa de salida\n","        self.fc3 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu1(x)\n","        x = self.fc2(x)\n","        x = self.relu2(x)\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":12,"id":"b62f0fdc-bfb8-4081-acfa-bcab5226b82e","metadata":{"id":"b62f0fdc-bfb8-4081-acfa-bcab5226b82e","executionInfo":{"status":"ok","timestamp":1726345242322,"user_tz":300,"elapsed":1538,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Crear el modelo\n","model = ImprovedNN(input_size, hidden_size, output_size)\n","\n","# Definir el criterio de pérdida y el optimizador\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":13,"id":"eb8b0c9b-55b2-4397-8a0d-e4b13fd2fbec","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eb8b0c9b-55b2-4397-8a0d-e4b13fd2fbec","outputId":"7edc1dc5-adaf-4815-a86c-a5ba720128d8","executionInfo":{"status":"ok","timestamp":1726345331127,"user_tz":300,"elapsed":87513,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [20/180], Loss: 7.5063, Train Accuracy: 1.93%, Test Accuracy: 1.83%\n","Epoch [40/180], Loss: 6.6460, Train Accuracy: 2.56%, Test Accuracy: 1.83%\n","Epoch [60/180], Loss: 5.7510, Train Accuracy: 7.17%, Test Accuracy: 6.59%\n","Epoch [80/180], Loss: 5.5864, Train Accuracy: 7.87%, Test Accuracy: 6.91%\n","Epoch [100/180], Loss: 5.5013, Train Accuracy: 7.59%, Test Accuracy: 6.99%\n","Epoch [120/180], Loss: 5.4314, Train Accuracy: 9.16%, Test Accuracy: 7.07%\n","Epoch [140/180], Loss: 5.3218, Train Accuracy: 11.74%, Test Accuracy: 8.18%\n","Epoch [160/180], Loss: 5.1450, Train Accuracy: 15.58%, Test Accuracy: 9.37%\n","Epoch [180/180], Loss: 4.9121, Train Accuracy: 20.23%, Test Accuracy: 9.93%\n"]}],"source":["# Entrenar el modelo\n","n_epochs = 180\n","\n","for epoch in range(n_epochs):\n","    model.train()\n","\n","    # Hacer predicciones y calcular la pérdida\n","    outputs = model(X_train)\n","    loss = criterion(outputs, y_train)\n","\n","    # Actualizar los pesos\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Calcular precisión en los datos de entrenamiento\n","    _, predicted = torch.max(outputs, 1)\n","    train_accuracy = accuracy_score(y_train, predicted)\n","\n","    # Evaluar en el conjunto de prueba\n","    model.eval()\n","    with torch.no_grad():\n","        outputs_test = model(X_test)\n","        _, predicted_test = torch.max(outputs_test, 1)\n","        test_accuracy = accuracy_score(y_test, predicted_test)\n","\n","    if (epoch+1) % 20 == 0:\n","        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy*100:.2f}%, Test Accuracy: {test_accuracy*100:.2f}%\")\n"]},{"cell_type":"code","execution_count":14,"id":"vgZF-xh23sd2","metadata":{"id":"vgZF-xh23sd2","executionInfo":{"status":"ok","timestamp":1726345351200,"user_tz":300,"elapsed":1,"user":{"displayName":"fgony","userId":"12699453911390145003"}}},"outputs":[],"source":["# Función para predecir la siguiente palabra dada una palabra\n","def predict_next_word(input_word):\n","    input_vectorized = vectorizer.transform([input_word]).toarray()\n","    input_tensor = torch.tensor(input_vectorized, dtype=torch.float32)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(input_tensor)\n","        probabilities = torch.softmax(output, dim=1)\n","        predicted_prob, predicted_idx = torch.max(probabilities, 1)\n","\n","    predicted_word = label_encoder.inverse_transform(predicted_idx.numpy())[0]\n","    return predicted_word, predicted_prob.item()"]},{"cell_type":"code","execution_count":15,"id":"1ac920e4-e9fc-4760-b031-9c959d78bae5","metadata":{"id":"1ac920e4-e9fc-4760-b031-9c959d78bae5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726345353590,"user_tz":300,"elapsed":441,"user":{"displayName":"fgony","userId":"12699453911390145003"}},"outputId":"fc9f54cd-d049-422b-8b36-97d0e9bf06b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n","aldea , de la la la la la la la la\n"]}],"source":["# Probar predicción\n","max_n_pred = 10\n","for _ in range(10):\n","  word = 'aldea'\n","  full_pred = word\n","  for i in range(max_n_pred):\n","    word2 = predict_next_word(word)[0]\n","    full_pred = full_pred + ' ' + word2\n","    word = word2\n","  print(full_pred)"]},{"cell_type":"markdown","id":"9e2d09aa-8a47-4668-b1b1-5080be8851ed","metadata":{"id":"9e2d09aa-8a47-4668-b1b1-5080be8851ed"},"source":["### Analysis"]},{"cell_type":"markdown","id":"2d06d9c5-4df1-4145-812f-ff86958154c1","metadata":{"id":"2d06d9c5-4df1-4145-812f-ff86958154c1"},"source":["1. Test your network with a few words"]},{"cell_type":"code","source":["def pred_n_words(word = 'buendia', max_n_pred = 10):\n","  full_pred = word\n","  l1 = 0\n","  for i in range(max_n_pred):\n","    word2 = predict_next_word(word)[0]\n","    pr = predict_next_word(word)[1]\n","    full_pred = full_pred + ' ' + word2\n","    word = word2\n","    l1 += np.log(pr)\n","\n","  n_ll = l1/max_n_pred\n","  print(full_pred, '| neg log:', n_ll)\n","\n","palabras = ['buendia', 'niño', 'posibilidad', 'casa', 'muchos']\n","for w in palabras:\n","  pred_n_words(word = w, max_n_pred =1)\n","print(' ')\n","for w in palabras:\n","  pred_n_words(word = w)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GsVoiWPI-zEY","executionInfo":{"status":"ok","timestamp":1726345357533,"user_tz":300,"elapsed":696,"user":{"displayName":"fgony","userId":"12699453911390145003"}},"outputId":"4368eed5-11cb-4538-bfc8-faf7796d3c02"},"id":"GsVoiWPI-zEY","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["buendia de | neg log: -3.309816360084446\n","niño de | neg log: -1.8394332701900957\n","posibilidad de | neg log: -0.1501823283726358\n","casa , | neg log: -1.903839449475963\n","muchos de | neg log: -2.4020923375421463\n"," \n","buendia de la la la la la la la la la | neg log: -5.30245997287211\n","niño de la la la la la la la la la | neg log: -5.1554216638826755\n","posibilidad de la la la la la la la la la | neg log: -4.986496569700929\n","casa , de la la la la la la la la | neg log: -4.9020894451768395\n","muchos de la la la la la la la la la | neg log: -5.2116875706178805\n"]}]},{"cell_type":"markdown","source":["2. What does each value in the tensor represents?\n","\n","Al ser un tensor de convolucion requiere de valores en forma matricial para funcionar de manera adecuada, por lo que el tensor proporcionado debe ajustarse."],"metadata":{"id":"UpI7BzmRVMHd"},"id":"UpI7BzmRVMHd"},{"cell_type":"markdown","id":"2d0e838c-3cab-4b6f-b041-1fde6a6d29aa","metadata":{"id":"2d0e838c-3cab-4b6f-b041-1fde6a6d29aa"},"source":["\n","3. Why does it make sense to choose that number of neurons in our layer?\n","\n","\n","Cada capa de entrada debe tener la misma cantidad de salida por que asi fue definido el biagram."]},{"cell_type":"markdown","source":["4. What's the negative likelihood for each example?\n","\n","Es una medida que nos ayuda a cuantificar segun el modelo propuesto que tan probable es que la palabra sea la verdadera."],"metadata":{"id":"J8GpiQPmVQQt"},"id":"J8GpiQPmVQQt"},{"cell_type":"markdown","source":["5. Try generating a few sentences?\n","\n","Se debe generar con un bucle para generar un amplio vocabulario y no repetir las mismas palabras en bucle cerrado.\n"],"metadata":{"id":"Y4WEgNGrVEnt"},"id":"Y4WEgNGrVEnt"},{"cell_type":"markdown","source":["6. What's the negative likelihood for each sentence?\n","\n","Vendria a ser la sumatoria de cada una de las palabras."],"metadata":{"id":"k5wfs-PaOfmx"},"id":"k5wfs-PaOfmx"},{"cell_type":"markdown","source":["### Design your own neural network (more layers and different number of neurons)\n","The goal is to get sentences that make more sense"],"metadata":{"id":"_GaMN9FeLyYV"},"id":"_GaMN9FeLyYV"},{"cell_type":"markdown","source":["##NUEVO INTENTO DEL MODELO\n"],"metadata":{"id":"NGGiQGauLsXB"},"id":"NGGiQGauLsXB"},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n","\n","# Tokenización a nivel de palabras\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([text])\n","total_words = len(tokenizer.word_index) + 1\n","\n","# Crear secuencias de bigramas\n","sequences = []\n","input_sequences = text.split()  # Dividir el texto en palabras\n","\n","for i in range(len(input_sequences) - 1):\n","    bigram = input_sequences[i:i+2]  # Crear bigramas de exactamente 2 palabras\n","    seq = tokenizer.texts_to_sequences([bigram])[0]  # Convertir bigrama a secuencia de índices\n","\n","    # Asegurarse de que la secuencia sea de longitud 2\n","    if len(seq) == 2:\n","        sequences.append(seq)\n","\n","# Convertir las secuencias a arrays de NumPy\n","sequences = np.array(sequences)\n","X, y = sequences[:, 0], sequences[:, 1]\n","X = np.expand_dims(X, axis=-1)  # Añadir una dimensión para que X tenga 3 dimensiones\n","\n","# Convertir etiquetas a one-hot encoding\n","y = to_categorical(y, num_classes=total_words)\n","\n","# Definir el modelo de predicción de palabras\n","model = Sequential()\n","model.add(Embedding(input_dim=total_words, output_dim=10, input_length=1))  # Embedding de una palabra\n","model.add(Bidirectional(LSTM(50)))  # La salida del embedding es 3D, compatible con LSTM\n","model.add(Dense(total_words, activation='softmax'))\n","\n","# Compilar el modelo\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Entrenar el modelo\n","model.fit(X, y, epochs=50, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ctrxFsVLrMR","executionInfo":{"status":"ok","timestamp":1726345436338,"user_tz":300,"elapsed":71596,"user":{"displayName":"fgony","userId":"12699453911390145003"}},"outputId":"2b4e9e39-3815-4bf3-d2a0-f5a916633396"},"id":"4ctrxFsVLrMR","execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","145/145 - 5s - 38ms/step - accuracy: 0.0894 - loss: 7.3735\n","Epoch 2/50\n","145/145 - 2s - 11ms/step - accuracy: 0.0920 - loss: 6.0652\n","Epoch 3/50\n","145/145 - 1s - 7ms/step - accuracy: 0.0920 - loss: 5.6774\n","Epoch 4/50\n","145/145 - 1s - 7ms/step - accuracy: 0.0920 - loss: 5.5525\n","Epoch 5/50\n","145/145 - 1s - 6ms/step - accuracy: 0.0920 - loss: 5.4678\n","Epoch 6/50\n","145/145 - 1s - 8ms/step - accuracy: 0.0926 - loss: 5.4052\n","Epoch 7/50\n","145/145 - 1s - 6ms/step - accuracy: 0.0924 - loss: 5.3458\n","Epoch 8/50\n","145/145 - 1s - 7ms/step - accuracy: 0.0924 - loss: 5.2752\n","Epoch 9/50\n","145/145 - 2s - 10ms/step - accuracy: 0.0931 - loss: 5.2073\n","Epoch 10/50\n","145/145 - 3s - 18ms/step - accuracy: 0.0987 - loss: 5.1355\n","Epoch 11/50\n","145/145 - 1s - 6ms/step - accuracy: 0.1163 - loss: 5.0509\n","Epoch 12/50\n","145/145 - 1s - 8ms/step - accuracy: 0.1312 - loss: 4.9583\n","Epoch 13/50\n","145/145 - 1s - 9ms/step - accuracy: 0.1358 - loss: 4.8586\n","Epoch 14/50\n","145/145 - 1s - 6ms/step - accuracy: 0.1384 - loss: 4.7540\n","Epoch 15/50\n","145/145 - 1s - 9ms/step - accuracy: 0.1575 - loss: 4.6526\n","Epoch 16/50\n","145/145 - 1s - 9ms/step - accuracy: 0.1668 - loss: 4.5545\n","Epoch 17/50\n","145/145 - 1s - 6ms/step - accuracy: 0.1839 - loss: 4.4596\n","Epoch 18/50\n","145/145 - 1s - 6ms/step - accuracy: 0.1989 - loss: 4.3675\n","Epoch 19/50\n","145/145 - 1s - 9ms/step - accuracy: 0.2226 - loss: 4.2731\n","Epoch 20/50\n","145/145 - 1s - 10ms/step - accuracy: 0.2566 - loss: 4.1747\n","Epoch 21/50\n","145/145 - 3s - 19ms/step - accuracy: 0.2657 - loss: 4.0802\n","Epoch 22/50\n","145/145 - 2s - 13ms/step - accuracy: 0.2746 - loss: 3.9862\n","Epoch 23/50\n","145/145 - 1s - 9ms/step - accuracy: 0.2768 - loss: 3.8939\n","Epoch 24/50\n","145/145 - 1s - 9ms/step - accuracy: 0.2822 - loss: 3.8097\n","Epoch 25/50\n","145/145 - 1s - 6ms/step - accuracy: 0.2907 - loss: 3.7269\n","Epoch 26/50\n","145/145 - 1s - 6ms/step - accuracy: 0.2974 - loss: 3.6510\n","Epoch 27/50\n","145/145 - 1s - 9ms/step - accuracy: 0.3043 - loss: 3.5787\n","Epoch 28/50\n","145/145 - 1s - 6ms/step - accuracy: 0.3154 - loss: 3.5101\n","Epoch 29/50\n","145/145 - 1s - 6ms/step - accuracy: 0.3210 - loss: 3.4485\n","Epoch 30/50\n","145/145 - 1s - 6ms/step - accuracy: 0.3262 - loss: 3.3867\n","Epoch 31/50\n","145/145 - 1s - 10ms/step - accuracy: 0.3299 - loss: 3.3276\n","Epoch 32/50\n","145/145 - 2s - 10ms/step - accuracy: 0.3343 - loss: 3.2719\n","Epoch 33/50\n","145/145 - 2s - 13ms/step - accuracy: 0.3451 - loss: 3.2183\n","Epoch 34/50\n","145/145 - 1s - 9ms/step - accuracy: 0.3501 - loss: 3.1687\n","Epoch 35/50\n","145/145 - 1s - 9ms/step - accuracy: 0.3614 - loss: 3.1198\n","Epoch 36/50\n","145/145 - 1s - 6ms/step - accuracy: 0.3627 - loss: 3.0792\n","Epoch 37/50\n","145/145 - 1s - 6ms/step - accuracy: 0.3764 - loss: 3.0346\n","Epoch 38/50\n","145/145 - 1s - 6ms/step - accuracy: 0.3809 - loss: 2.9936\n","Epoch 39/50\n","145/145 - 1s - 9ms/step - accuracy: 0.3866 - loss: 2.9548\n","Epoch 40/50\n","145/145 - 1s - 8ms/step - accuracy: 0.3872 - loss: 2.9192\n","Epoch 41/50\n","145/145 - 1s - 6ms/step - accuracy: 0.3959 - loss: 2.8839\n","Epoch 42/50\n","145/145 - 2s - 13ms/step - accuracy: 0.3959 - loss: 2.8518\n","Epoch 43/50\n","145/145 - 2s - 10ms/step - accuracy: 0.3967 - loss: 2.8207\n","Epoch 44/50\n","145/145 - 2s - 13ms/step - accuracy: 0.3993 - loss: 2.7915\n","Epoch 45/50\n","145/145 - 2s - 13ms/step - accuracy: 0.4052 - loss: 2.7616\n","Epoch 46/50\n","145/145 - 1s - 8ms/step - accuracy: 0.4063 - loss: 2.7348\n","Epoch 47/50\n","145/145 - 1s - 6ms/step - accuracy: 0.4065 - loss: 2.7097\n","Epoch 48/50\n","145/145 - 1s - 9ms/step - accuracy: 0.4130 - loss: 2.6865\n","Epoch 49/50\n","145/145 - 1s - 6ms/step - accuracy: 0.4154 - loss: 2.6650\n","Epoch 50/50\n","145/145 - 1s - 6ms/step - accuracy: 0.4108 - loss: 2.6448\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x79c08129ea10>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Función para predecir la siguiente palabra basada en un bigrama dado\n","def predict_next_word(input_text, model, tokenizer, total_words):\n","    input_seq = tokenizer.texts_to_sequences([input_text.split()])[-1]  # Convertir el bigrama en secuencia de índices\n","\n","    # Si el bigrama tiene más de una palabra, solo tomamos la última\n","    input_seq = np.array([input_seq[-1]])  # Convertimos a numpy array y obtenemos el último token\n","    input_seq = np.expand_dims(input_seq, axis=-1)  # Asegurarse de que la entrada sea 3D como espera el modelo\n","\n","    # Predecir la próxima palabra\n","    prediction = model.predict(input_seq)\n","    predicted_word_index = np.argmax(prediction, axis=-1)[0]  # Obtener el índice de la palabra predicha\n","\n","    # Convertir el índice predicho a la palabra correspondiente\n","    predicted_word = tokenizer.index_word[predicted_word_index]\n","    return predicted_word\n","\n","# Texto de prueba\n","input_bigram = \"Aureliano\"  # Por ejemplo, un bigrama en tu dataset de prueba\n","predicted_word = predict_next_word(input_bigram, model, tokenizer, total_words)\n","print(f\"Predicción para el bigrama '{input_bigram}': {predicted_word}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8fTbcV-NU0l","executionInfo":{"status":"ok","timestamp":1726345482240,"user_tz":300,"elapsed":1502,"user":{"displayName":"fgony","userId":"12699453911390145003"}},"outputId":"eb83f14a-789a-4c6f-d233-5eda10dd2f6c"},"id":"G8fTbcV-NU0l","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","Predicción para el bigrama 'Aureliano': buendía\n"]}]},{"cell_type":"code","source":["def generate_sentence(seed_text, model, tokenizer, total_words, max_words=20):\n","    for _ in range(max_words):\n","        # Predecir la siguiente palabra\n","        predicted_word = predict_next_word(seed_text, model, tokenizer, total_words)\n","\n","        # Añadir la palabra predicha a la semilla de texto\n","        seed_text += \" \" + predicted_word\n","\n","        # Detener la generación si se encuentra un punto (.)\n","        if predicted_word == '.':\n","            break\n","\n","    return seed_text\n","\n","# Iniciar con un bigrama de prueba\n","seed_text = \"Aureliano\"\n","predicted_sentence = generate_sentence(seed_text, model, tokenizer, total_words, max_words=10)\n","\n","print(f\"Oración generada: {predicted_sentence}\")\n","# Iniciar con un bigrama de prueba\n","seed_text = \"palabras\"\n","predicted_sentence = generate_sentence(seed_text, model, tokenizer, total_words, max_words=10)\n","\n","print(f\"Oración generada: {predicted_sentence}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75iCF9jxNcik","executionInfo":{"status":"ok","timestamp":1726345501361,"user_tz":300,"elapsed":1963,"user":{"displayName":"fgony","userId":"12699453911390145003"}},"outputId":"1f76b427-e595-4ca1-8d79-b1cecfcef1cc"},"id":"75iCF9jxNcik","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","Oración generada: Aureliano buendía no había de su padre lo llevó a la\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Oración generada: palabras de su padre lo llevó a la aldea e implacable\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}